# main.py â€“ RFMiD Retina HastalÄ±k Tespiti Projesi

# ğŸ“¦ 1. Gerekli KÃ¼tÃ¼phaneler
import os
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from tqdm import tqdm
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import BinaryAccuracy, AUC
from sklearn.model_selection import train_test_split

# ğŸ“ 2. Ã‡alÄ±ÅŸma Dizini ve Yol AyarlarÄ±
BASE_DIR = r"D:/Yapay zeka eÄŸitme/Retinal HastalÄ±klarÄ±n Tespiti/RFMiD"
DATA_DIR = os.path.join(BASE_DIR, "data")
TRAIN_DIR = os.path.join(DATA_DIR, "Train")
TRAIN_CSV = os.path.join(DATA_DIR, "RFMiD_Training_Labels.csv")
# Test klasÃ¶rÃ¼ ve test etiket dosyasÄ±
TEST_DIR = os.path.join(DATA_DIR, "Test")
TEST_CSV = os.path.join(DATA_DIR, "RFMiD_Testing_Labels.csv")


# ğŸ§ª 3. EÄŸitim Verisini YÃ¼kle
if not os.path.exists(TRAIN_CSV):
    raise FileNotFoundError(f"EÄŸitim CSV dosyasÄ± bulunamadÄ±: {TRAIN_CSV}\nLÃ¼tfen dosyanÄ±n yÃ¼klenip doÄŸru klasÃ¶rde olduÄŸundan emin olun.")

df_train = pd.read_csv(TRAIN_CSV)
print("ğŸ“‹ EÄŸitim etiketlerinden ilk 5 satÄ±r:")
print(df_train.head())

# ğŸ”¹ Sadece ilk 300 eÄŸitim verisiyle Ã§alÄ±ÅŸ
df_train = df_train.head(200)

# ğŸ”— 4. GÃ¶rsel Yolu Ekle (PNG uzantÄ±lÄ± gÃ¶rseller iÃ§in)
df_train["image_path"] = df_train["ID"].apply(lambda x: os.path.join(TRAIN_DIR, f"{x}.png"))

# ğŸ–¼ï¸ 5. Ã–rnek GÃ¶rsel GÃ¶ster
sample_path = df_train["image_path"].iloc[0]
if not os.path.exists(sample_path):
    raise FileNotFoundError(f"Ã–rnek gÃ¶rsel bulunamadÄ±: {sample_path}\nLÃ¼tfen 'train' klasÃ¶rÃ¼ndeki gÃ¶rsellerin doÄŸru yÃ¼klendiÄŸini kontrol edin.")

img = Image.open(sample_path)
plt.imshow(img)
plt.title(f"GÃ¶rsel: {df_train['ID'].iloc[0]}")
plt.axis("off")
plt.show()

# ğŸ” 6. Etiket DaÄŸÄ±lÄ±mÄ± Analizi
label_columns = df_train.columns[1:-1]  # Disease_Risk dahil, image_path hariÃ§ olmalÄ±
print("Etiket sÃ¼tunlarÄ±:", label_columns.tolist())

df_train["label_count"] = df_train[label_columns].sum(axis=1)
print("ğŸ”¢ Ortalama etiket sayÄ±sÄ±:", df_train["label_count"].mean())

# ğŸ“Š 7. Etiket SayÄ±sÄ± GrafiÄŸi
label_counts = df_train[label_columns].sum().sort_values(ascending=False)
plt.figure(figsize=(12, 5))
label_counts.plot(kind="bar")
plt.title("Etiket DaÄŸÄ±lÄ±mÄ± (Her HastalÄ±k)")
plt.xlabel("HastalÄ±k")
plt.ylabel("Toplam GÃ¶rsel SayÄ±sÄ±")
plt.xticks(rotation=90)
plt.grid(True)
plt.tight_layout()
plt.show()

# ğŸ“ Parametreler
IMG_SIZE = 224

# load_data fonksiyonunu label_columns parametresi alacak ÅŸekilde gÃ¼ncelleyelim:
def load_data(df, label_columns=None, img_size=224):
    X = []
    y = []
    if label_columns is None:
        label_columns = [col for col in df.columns if col not in ["ID", "Disease_Risk", "image_path"]]

    print("ğŸ”„ GÃ¶rseller yÃ¼kleniyor...")
    for _, row in tqdm(df.iterrows(), total=len(df)):
        path = row["image_path"]
        if os.path.exists(path):
            try:
                img = Image.open(path).convert("RGB")
                img = img.resize((img_size, img_size))
                img_array = np.array(img) / 255.0  # normalize
                X.append(img_array)
                labels = np.clip(row[label_columns].astype(np.float32).values, 0, 1)
                y.append(labels)
            except Exception as e:
                print(f"âš ï¸ Hata oluÅŸtu: {e} - {path}")
        else:
            print(f"âš ï¸ GÃ¶rsel bulunamadÄ±: {path}")

    return np.array(X), np.array(y)
         
X_train, y_train = load_data(df_train)
print(f"âœ… X_train ÅŸekli: {X_train.shape}")
print(f"âœ… y_train ÅŸekli: {y_train.shape}")

# ğŸ“Š EÄŸitim/DoÄŸrulama AyÄ±rÄ±mÄ±
X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42
)

# ğŸ§  Model OluÅŸtur
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(y_train.shape[1], activation='sigmoid')
])

# âœ… Derleme
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=[BinaryAccuracy(), AUC()])

# ğŸš€ Modeli EÄŸit
history = model.fit(
    X_train_split, y_train_split,
    validation_data=(X_val_split, y_val_split),
    epochs=10,
    batch_size=32
)
print("Son epoch eÄŸitim doÄŸruluÄŸu: {:.2f}%".format(history.history['binary_accuracy'][-1] * 100))
print("Son epoch doÄŸrulama doÄŸruluÄŸu: {:.2f}%".format(history.history['val_binary_accuracy'][-1] * 100))


# ğŸ“ˆ BaÅŸarÄ± Grafikleri
plt.plot(history.history['binary_accuracy'], label='EÄŸitim DoÄŸruluk')
plt.plot(history.history['val_binary_accuracy'], label='DoÄŸrulama DoÄŸruluk')
plt.title('DoÄŸruluk (Binary Accuracy)')
plt.xlabel('Epoch')
plt.ylabel('BaÅŸarÄ±')
plt.legend()
plt.grid(True)
plt.show()

plt.plot(history.history['loss'], label='EÄŸitim KayÄ±p')
plt.plot(history.history['val_loss'], label='DoÄŸrulama KayÄ±p')
plt.title('KayÄ±p (Loss)')
plt.xlabel('Epoch')
plt.ylabel('Hata')
plt.legend()
plt.grid(True)
plt.show()

# ğŸ“„ Test etiketlerini yÃ¼kle ve gÃ¶rsel yolunu tanÄ±mla
print("ğŸ” Test verisi hazÄ±rlanÄ±yor...")
df_test = pd.read_csv(TEST_CSV)
# ğŸ”¹ Sadece ilk 100 test verisiyle Ã§alÄ±ÅŸ
df_test = df_test.head(100)
df_test["image_path"] = df_test["ID"].apply(lambda x: os.path.join(TEST_DIR, f"{x}.png"))

# ğŸ› ï¸ Etiket sÃ¼tunlarÄ±nÄ± sÄ±fÄ±rdan kur (eÄŸitimdeki etiketlere gÃ¶re)
for col in label_columns:
    if col not in df_test.columns:
        df_test[col] = 0  # Eksik etiketleri sÄ±fÄ±rla tamamla

# ğŸ“ Test verisini yeniden yÃ¼kle
X_test, y_test = load_data(df_test, label_columns=label_columns)

print(f"âœ… X_test ÅŸekli: {X_test.shape}")
print(f"âœ… y_test ÅŸekli: {y_test.shape}")
print(f"âœ… X_test.shape: {X_test.shape}")
print(f"âœ… y_test.shape: {y_test.shape}")


# ğŸ“Š Modeli test verisiyle deÄŸerlendir
print("ğŸ“Š Test verisi deÄŸerlendiriliyor...")
results = model.evaluate(X_test, y_test, batch_size=8)


# ğŸ§¾ MetriÄŸi yazdÄ±r
for name, val in zip(model.metrics_names, results):
    if 'accuracy' in name or 'binary_accuracy' in name:
        print(f"{name}: {val * 100:.2f}%")
    else:
        print(f"{name}: {val:.4f}")

# ğŸ” EÄŸitilen modeli .h5 dosyasÄ± olarak kaydet
model_path = os.path.join(BASE_DIR, "model", "rfmid_model.h5")
os.makedirs(os.path.dirname(model_path), exist_ok=True)  # model klasÃ¶rÃ¼ yoksa oluÅŸtur
model.save(model_path)

print(f"âœ… Model .h5 formatÄ±nda kaydedildi: {model_path}")
















